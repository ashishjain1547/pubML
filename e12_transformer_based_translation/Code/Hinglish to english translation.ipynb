{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1725145f-dbb2-492b-86fd-0a567a8c03d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras_transformer import get_model, decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2f7e79ec-e96d-494d-8af4-58e7588d3eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Dataset/English_Hindi_Hinglish.txt', mode = 'r') as f:\n",
    "    data = f.readlines()\n",
    "\n",
    "data = data[0:195] # 195Because we have that many labeled data points for Hinglish to English translation.\n",
    "\n",
    "source_tokens = [i.split(',')[1].strip().split(' ') for i in data]\n",
    "target_tokens = [i.split('\t')[0].strip().split(' ') for i in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "23635da8-ab33-4912-bed3-e512926d21f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['wah!'],\n",
       " ['bachao!'],\n",
       " ['ucchlo.'],\n",
       " ['kudo.'],\n",
       " ['chhalang.'],\n",
       " ['namaste!'],\n",
       " ['namaskar!'],\n",
       " ['wah-wah!'],\n",
       " ['cheers!'],\n",
       " ['samajhe', 'ki', 'nhi?'],\n",
       " ['Mai', 'theek', 'hu!'],\n",
       " ['bahut', 'badiya!'],\n",
       " ['andar', 'aa', 'jao!'],\n",
       " ['bahar', 'nikal', 'jao!'],\n",
       " ['chale', 'jao!'],\n",
       " ['khuda', 'hafiz!'],\n",
       " ['uttam!'],\n",
       " ['sahi!'],\n",
       " ['apka', 'swagat', 'hai.'],\n",
       " ['swagatam.'],\n",
       " ['maze', 'karna.'],\n",
       " ['mauj', 'karna.'],\n",
       " ['maze', 'karo.'],\n",
       " ['mai', 'bhool', 'gaya.'],\n",
       " ['mai', 'bool', 'gayi.'],\n",
       " ['mai', 'paise', 'dunga.'],\n",
       " ['mai', 'theek', 'hu.'],\n",
       " ['mera', 'pet', 'bhar', 'gaya', 'hai.'],\n",
       " ['chale', 'jao.'],\n",
       " ['mujhe', 'jawab', 'do.'],\n",
       " ['pancchi', 'udte', 'hain.'],\n",
       " ['maaf', 'kijiye.'],\n",
       " ['bahut', 'khoob.'],\n",
       " ['mai', 'behosh', 'ho', 'gaya.'],\n",
       " ['लेकिन', 'वैसा', 'ही', 'है।'],\n",
       " ['mai', 'hansa.'],\n",
       " ['mai', 'bore', 'ho', 'rha', 'hu.'],\n",
       " ['mera', 'diwaliya', 'ho', 'chuka', 'hai.'],\n",
       " ['mai', 'thak', 'gaya', 'hu.'],\n",
       " ['thand', 'ho', 'rhi', 'hai.'],\n",
       " ['kaun', 'jane?'],\n",
       " ['kisko', 'pata', 'hai?'],\n",
       " ['kise', 'pata', 'hai?'],\n",
       " ['kise', 'malum', 'hai?'],\n",
       " ['adbhut!'],\n",
       " ['panchhi', 'gate', 'hai.'],\n",
       " ['andar', 'aa', 'jao.'],\n",
       " ['nishchit', 'hi!'],\n",
       " ['hilo', 'mat.'],\n",
       " ['aag', 'jalaati', 'hai.'],\n",
       " ['uska', 'pichha', 'karo.'],\n",
       " ['mai', 'thak', 'gaya', 'hu.'],\n",
       " ['mujhe', 'tairna', 'ata', 'hai.'],\n",
       " ['mai', 'tair', 'sakta', 'hu.'],\n",
       " ['mai', 'tumse', 'pyar', 'karti', 'hu.'],\n",
       " ['mai', 'tumse', 'pyar', 'karta', 'hu.'],\n",
       " ['mai', 'aapse', 'pyar', 'karta', 'hu.'],\n",
       " ['mai', 'aapse', 'pyar', 'karti', 'hu.'],\n",
       " ['mujhe', 'tumse', 'pyar', 'hai.'],\n",
       " ['mai', 'koshish', 'karunga.'],\n",
       " ['mai', 'aa', 'raha', 'hu.'],\n",
       " ['mujhe', 'bhookh', 'lagi', 'hai!'],\n",
       " ['use', 'andar', 'bhejo.'],\n",
       " ['use', 'andar', 'aane', 'do.'],\n",
       " ['mujhe', 'bahar', 'jane', 'do!'],\n",
       " ['or', 'ek', 'baar.'],\n",
       " ['baithiye.'],\n",
       " ['kya', 'naya', 'hai?'],\n",
       " ['naya', 'kya', 'hai?'],\n",
       " ['vo', 'kaun', 'hai?'],\n",
       " ['chilaao', 'mat.'],\n",
       " ['chilaiye', 'mat.'],\n",
       " ['mai', 'khada', 'ho', 'gaya.'],\n",
       " ['vo', 'takatwar', 'hai.'],\n",
       " ['kaise', 'ho?'],\n",
       " ['aap', 'kaise', 'hai?'],\n",
       " ['tum', 'kaise', 'ho?'],\n",
       " ['tum', 'kaisi', 'ho?'],\n",
       " ['tu', 'kaisa', 'hai?'],\n",
       " ['tu', 'kaisi', 'hai?'],\n",
       " ['aap', 'kaise', 'hai?'],\n",
       " ['aap', 'kaise', 'ho?'],\n",
       " ['mujhe', 'dono', 'pasand', 'hai.'],\n",
       " ['mujhe', 'cake', 'accha', 'lagta', 'hai.'],\n",
       " ['mujhe', 'kutte', 'acche', 'lagte', 'hai.'],\n",
       " ['mujhe', 'ganit', 'pasand', 'hai.'],\n",
       " ['mai', 'aaunga.'],\n",
       " ['koi', 'nahi', 'aya.'],\n",
       " ['kya', 'mai', 'galat', 'tha?'],\n",
       " ['ye', 'kya', 'hai?'],\n",
       " ['kya', 'tum', 'bimaar', 'ho?'],\n",
       " ['usko', 'andar', 'le', 'aao.'],\n",
       " ['hamare', 'saath', 'aao.'],\n",
       " ['easter', 'mubarak', 'ho!'],\n",
       " ['tom', 'chala', 'gaya', 'kya?'],\n",
       " ['vo', 'fransisi', 'hai.'],\n",
       " ['mai', 'ghar', 'par', 'hu.'],\n",
       " ['mai', 'hil', 'nhi', 'sakta.'],\n",
       " ['mujhe', 'nhi', 'pata.'],\n",
       " ['mujhe', 'nhi', 'malum.'],\n",
       " ['mere', 'paas', 'ek', 'gadi', 'hai.'],\n",
       " ['mere', 'paas', 'ek', 'kutta', 'hai.'],\n",
       " ['mai', 'samajhta', 'hu.'],\n",
       " ['mai', 'doctor', 'hu.'],\n",
       " ['mai', 'bhookh', 'se', 'mara', 'jaa', 'rha', 'hu.'],\n",
       " ['ye', 'kitaab', 'hai.'],\n",
       " ['baraf', 'gir', 'rhi', 'hai.'],\n",
       " ['yeh', 'bahut', 'jyada', 'bada', 'hai.'],\n",
       " ['kripya', 'jaaiye.'],\n",
       " ['avishvasneeya!'],\n",
       " ['hum', 'khush', 'hai.'],\n",
       " ['ye', 'kya', 'hai?'],\n",
       " ['thak', 'gaye', 'ho', 'kya?'],\n",
       " ['tum', 'gadi', 'chala', 'sakte', 'ho', 'kya?'],\n",
       " ['mote', 'mat', 'ho', 'jana.'],\n",
       " ['haar', 'mat', 'maan', 'lo.'],\n",
       " ['peekar', 'khatam', 'kardo.'],\n",
       " ['maut', 'toh', 'sabhi', 'ki', 'hoti', 'hai.'],\n",
       " ['fool', 'khilte', 'hai.'],\n",
       " ['mai', 'hu', 'jo', 'hu.'],\n",
       " ['mai', 'use', 'le', 'lunga.'],\n",
       " ['mai', 'ab', 'thak', 'gaya', 'hu.'],\n",
       " ['mai', 'bahut', 'vyast', 'hu.'],\n",
       " ['vo', 'billi', 'hai', 'kya?'],\n",
       " ['ye', 'muft', 'hai.'],\n",
       " ['ye', 'muft', 'ka', 'hai.'],\n",
       " ['mujhe', 'dikhao.'],\n",
       " ['mujhe', 'dekhne', 'do.'],\n",
       " ['mujhe', 'try', 'karne', 'do.'],\n",
       " ['jaldi', 'kijiye.'],\n",
       " ['mai', 'andar', 'aa', 'sakta', 'hu', 'kya?'],\n",
       " ['darwaaza', 'kholo.'],\n",
       " ['darwaaza', 'kholiye.'],\n",
       " ['kripya', 'andar', 'aaiye.'],\n",
       " ['ise', 'dobara', 'padhe.'],\n",
       " ['padke', 'sunao.'],\n",
       " ['vo', 'niche', 'jhuki.'],\n",
       " ['kuch', 'macchliya', 'ud', 'sakti', 'hai.'],\n",
       " ['ye', 'naksha', 'hai.'],\n",
       " ['tom', 'mera', 'ladka', 'hai.'],\n",
       " ['ham', 'shahar', 'mei', 'hai.'],\n",
       " ['kya', 'tumhe', 'goli', 'lag', 'gai', 'thi?'],\n",
       " ['hamara', 'kya?'],\n",
       " ['kya', 'mai', 'aapki', 'sahayta', 'kar', 'sakta', 'hu?'],\n",
       " ['kya', 'mai', 'aapki', 'madad', 'kar', 'sakta', 'hu?'],\n",
       " ['kamre', 'ko', 'saaf', 'karo.'],\n",
       " ['use', 'cchuna', 'mat.'],\n",
       " ['bistar', 'se', 'bahar', 'niklo!'],\n",
       " ['nav', 'varsh', 'ki', 'shubhkamnaaei!'],\n",
       " ['naye', 'saal', 'ki', 'badhaiyaa!'],\n",
       " ['janmadin', 'mubarak', 'ho!'],\n",
       " ['uske', 'paas', 'dadhi', 'hai.'],\n",
       " ['vo', 'abhineta', 'hai.'],\n",
       " ['use', 'paiso', 'ki', 'zarurat', 'hai.'],\n",
       " ['usko', 'paiso', 'ki', 'kami', 'thi.'],\n",
       " ['mujhe', 'itihaas', 'pasand', 'hai.'],\n",
       " ['mujhe', 'ye', 'kutta', 'acha', 'lagta', 'hai.'],\n",
       " ['mujhe', 'ek', 'toh', 'kharidna', 'hi', 'hoga.'],\n",
       " ['mai', 'vaapas', 'aaunga.'],\n",
       " ['mai', 'tumhe', 'phone', 'karunga.'],\n",
       " ['mai', 'ghar', 'par', 'hi', 'rahunga.'],\n",
       " ['mai', 'anishwarvadi', 'hu.'],\n",
       " ['mai', 'bhagwan', 'mei', 'yakin', 'nhi', 'karta.'],\n",
       " ['mai', 'bahut', 'thak', 'gaya', 'hu.'],\n",
       " ['aaj', 'mausam', 'bahut', 'garam', 'hai.'],\n",
       " ['ye', 'kitab', 'hai.'],\n",
       " ['tumari', 'chaal', 'hai.'],\n",
       " ['bhagwan', 'jaane.'],\n",
       " ['garmiya', 'khatam', 'ho', 'chuki', 'hai.'],\n",
       " ['aaraam', 'se', 'aao.'],\n",
       " ['soch', 'lo.'],\n",
       " ['ye', 'ek', 'kitab', 'hai.'],\n",
       " ['ye', 'kitab', 'hai.'],\n",
       " ['ye', 'mera', 'basta', 'hai.'],\n",
       " ['ye', 'mera', 'kutta', 'hai.'],\n",
       " ['apne', 'paer', 'dho.'],\n",
       " ['ham', 'sangeet', 'ki', 'padhai', 'karte', 'hai.'],\n",
       " ['ham', 'apko', 'phone', 'karenge.'],\n",
       " ['ham', 'apko', 'bulaenge.'],\n",
       " ['tum', 'kaha', 'the?'],\n",
       " ['aap', 'kaha', 'the?'],\n",
       " ['tumhe', 'jana', 'hoga.'],\n",
       " ['tum', 'thake', 'hare', 'se', 'lagte', 'ho.'],\n",
       " ['mazaak', 'kar', 'rahe', 'ho!'],\n",
       " ['ek', 'aadmi', 'ke', 'liye', 'kaam', 'karna', 'jaruri', 'hai.'],\n",
       " ['tum', 'ghar', 'pe', 'ho', 'kya?'],\n",
       " ['kya', 'aap', 'log', 'theek', 'ho?'],\n",
       " ['jaldi', 'ghar', 'aa', 'jao.'],\n",
       " ['aa', 'sako', 'toh', 'aana.'],\n",
       " ['badhai', 'ho!'],\n",
       " ['mubarak', 'ho!'],\n",
       " ['vo', 'vaha', 'gaya', 'kya?'],\n",
       " ['meri', 'yaad', 'aai', 'kya?'],\n",
       " ['pagal', 'mat', 'bano.'],\n",
       " ['vo', 'bhagte', 'hue', 'aaya.']]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f16a0fdf-fb5c-4b39-8656-32540b2e853b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Encoder-Input (InputLayer)     [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " Encoder-Token-Embedding (Embed  [(None, None, 32),  10528       ['Encoder-Input[0][0]']          \n",
      " dingRet)                        (329, 32)]                                                       \n",
      "                                                                                                  \n",
      " Encoder-Embedding (TrigPosEmbe  (None, None, 32)    0           ['Encoder-Token-Embedding[0][0]']\n",
      " dding)                                                                                           \n",
      "                                                                                                  \n",
      " Encoder-1-MultiHeadSelfAttenti  (None, None, 32)    4224        ['Encoder-Embedding[0][0]']      \n",
      " on (MultiHeadAttention)                                                                          \n",
      "                                                                                                  \n",
      " Encoder-1-MultiHeadSelfAttenti  (None, None, 32)    0           ['Encoder-1-MultiHeadSelfAttentio\n",
      " on-Dropout (Dropout)                                            n[0][0]']                        \n",
      "                                                                                                  \n",
      " Encoder-1-MultiHeadSelfAttenti  (None, None, 32)    0           ['Encoder-Embedding[0][0]',      \n",
      " on-Add (Add)                                                     'Encoder-1-MultiHeadSelfAttentio\n",
      "                                                                 n-Dropout[0][0]']                \n",
      "                                                                                                  \n",
      " Encoder-1-MultiHeadSelfAttenti  (None, None, 32)    64          ['Encoder-1-MultiHeadSelfAttentio\n",
      " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
      "                                                                                                  \n",
      " Encoder-1-FeedForward (FeedFor  (None, None, 32)    8352        ['Encoder-1-MultiHeadSelfAttentio\n",
      " ward)                                                           n-Norm[0][0]']                   \n",
      "                                                                                                  \n",
      " Encoder-1-FeedForward-Dropout   (None, None, 32)    0           ['Encoder-1-FeedForward[0][0]']  \n",
      " (Dropout)                                                                                        \n",
      "                                                                                                  \n",
      " Encoder-1-FeedForward-Add (Add  (None, None, 32)    0           ['Encoder-1-MultiHeadSelfAttentio\n",
      " )                                                               n-Norm[0][0]',                   \n",
      "                                                                  'Encoder-1-FeedForward-Dropout[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " Encoder-1-FeedForward-Norm (La  (None, None, 32)    64          ['Encoder-1-FeedForward-Add[0][0]\n",
      " yerNormalization)                                               ']                               \n",
      "                                                                                                  \n",
      " Encoder-2-MultiHeadSelfAttenti  (None, None, 32)    4224        ['Encoder-1-FeedForward-Norm[0][0\n",
      " on (MultiHeadAttention)                                         ]']                              \n",
      "                                                                                                  \n",
      " Decoder-Input (InputLayer)     [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " Encoder-2-MultiHeadSelfAttenti  (None, None, 32)    0           ['Encoder-2-MultiHeadSelfAttentio\n",
      " on-Dropout (Dropout)                                            n[0][0]']                        \n",
      "                                                                                                  \n",
      " Decoder-Token-Embedding (Embed  [(None, None, 32),  10528       ['Decoder-Input[0][0]']          \n",
      " dingRet)                        (329, 32)]                                                       \n",
      "                                                                                                  \n",
      " Encoder-2-MultiHeadSelfAttenti  (None, None, 32)    0           ['Encoder-1-FeedForward-Norm[0][0\n",
      " on-Add (Add)                                                    ]',                              \n",
      "                                                                  'Encoder-2-MultiHeadSelfAttentio\n",
      "                                                                 n-Dropout[0][0]']                \n",
      "                                                                                                  \n",
      " Decoder-Embedding (TrigPosEmbe  (None, None, 32)    0           ['Decoder-Token-Embedding[0][0]']\n",
      " dding)                                                                                           \n",
      "                                                                                                  \n",
      " Encoder-2-MultiHeadSelfAttenti  (None, None, 32)    64          ['Encoder-2-MultiHeadSelfAttentio\n",
      " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
      "                                                                                                  \n",
      " Decoder-1-MultiHeadSelfAttenti  (None, None, 32)    4224        ['Decoder-Embedding[0][0]']      \n",
      " on (MultiHeadAttention)                                                                          \n",
      "                                                                                                  \n",
      " Encoder-2-FeedForward (FeedFor  (None, None, 32)    8352        ['Encoder-2-MultiHeadSelfAttentio\n",
      " ward)                                                           n-Norm[0][0]']                   \n",
      "                                                                                                  \n",
      " Decoder-1-MultiHeadSelfAttenti  (None, None, 32)    0           ['Decoder-1-MultiHeadSelfAttentio\n",
      " on-Dropout (Dropout)                                            n[0][0]']                        \n",
      "                                                                                                  \n",
      " Encoder-2-FeedForward-Dropout   (None, None, 32)    0           ['Encoder-2-FeedForward[0][0]']  \n",
      " (Dropout)                                                                                        \n",
      "                                                                                                  \n",
      " Decoder-1-MultiHeadSelfAttenti  (None, None, 32)    0           ['Decoder-Embedding[0][0]',      \n",
      " on-Add (Add)                                                     'Decoder-1-MultiHeadSelfAttentio\n",
      "                                                                 n-Dropout[0][0]']                \n",
      "                                                                                                  \n",
      " Encoder-2-FeedForward-Add (Add  (None, None, 32)    0           ['Encoder-2-MultiHeadSelfAttentio\n",
      " )                                                               n-Norm[0][0]',                   \n",
      "                                                                  'Encoder-2-FeedForward-Dropout[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " Decoder-1-MultiHeadSelfAttenti  (None, None, 32)    64          ['Decoder-1-MultiHeadSelfAttentio\n",
      " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
      "                                                                                                  \n",
      " Encoder-2-FeedForward-Norm (La  (None, None, 32)    64          ['Encoder-2-FeedForward-Add[0][0]\n",
      " yerNormalization)                                               ']                               \n",
      "                                                                                                  \n",
      " Decoder-1-MultiHeadQueryAttent  (None, None, 32)    4224        ['Decoder-1-MultiHeadSelfAttentio\n",
      " ion (MultiHeadAttention)                                        n-Norm[0][0]',                   \n",
      "                                                                  'Encoder-2-FeedForward-Norm[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'Encoder-2-FeedForward-Norm[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " Decoder-1-MultiHeadQueryAttent  (None, None, 32)    0           ['Decoder-1-MultiHeadQueryAttenti\n",
      " ion-Dropout (Dropout)                                           on[0][0]']                       \n",
      "                                                                                                  \n",
      " Decoder-1-MultiHeadQueryAttent  (None, None, 32)    0           ['Decoder-1-MultiHeadSelfAttentio\n",
      " ion-Add (Add)                                                   n-Norm[0][0]',                   \n",
      "                                                                  'Decoder-1-MultiHeadQueryAttenti\n",
      "                                                                 on-Dropout[0][0]']               \n",
      "                                                                                                  \n",
      " Decoder-1-MultiHeadQueryAttent  (None, None, 32)    64          ['Decoder-1-MultiHeadQueryAttenti\n",
      " ion-Norm (LayerNormalization)                                   on-Add[0][0]']                   \n",
      "                                                                                                  \n",
      " Decoder-1-FeedForward (FeedFor  (None, None, 32)    8352        ['Decoder-1-MultiHeadQueryAttenti\n",
      " ward)                                                           on-Norm[0][0]']                  \n",
      "                                                                                                  \n",
      " Decoder-1-FeedForward-Dropout   (None, None, 32)    0           ['Decoder-1-FeedForward[0][0]']  \n",
      " (Dropout)                                                                                        \n",
      "                                                                                                  \n",
      " Decoder-1-FeedForward-Add (Add  (None, None, 32)    0           ['Decoder-1-MultiHeadQueryAttenti\n",
      " )                                                               on-Norm[0][0]',                  \n",
      "                                                                  'Decoder-1-FeedForward-Dropout[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " Decoder-1-FeedForward-Norm (La  (None, None, 32)    64          ['Decoder-1-FeedForward-Add[0][0]\n",
      " yerNormalization)                                               ']                               \n",
      "                                                                                                  \n",
      " Decoder-2-MultiHeadSelfAttenti  (None, None, 32)    4224        ['Decoder-1-FeedForward-Norm[0][0\n",
      " on (MultiHeadAttention)                                         ]']                              \n",
      "                                                                                                  \n",
      " Decoder-2-MultiHeadSelfAttenti  (None, None, 32)    0           ['Decoder-2-MultiHeadSelfAttentio\n",
      " on-Dropout (Dropout)                                            n[0][0]']                        \n",
      "                                                                                                  \n",
      " Decoder-2-MultiHeadSelfAttenti  (None, None, 32)    0           ['Decoder-1-FeedForward-Norm[0][0\n",
      " on-Add (Add)                                                    ]',                              \n",
      "                                                                  'Decoder-2-MultiHeadSelfAttentio\n",
      "                                                                 n-Dropout[0][0]']                \n",
      "                                                                                                  \n",
      " Decoder-2-MultiHeadSelfAttenti  (None, None, 32)    64          ['Decoder-2-MultiHeadSelfAttentio\n",
      " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
      "                                                                                                  \n",
      " Decoder-2-MultiHeadQueryAttent  (None, None, 32)    4224        ['Decoder-2-MultiHeadSelfAttentio\n",
      " ion (MultiHeadAttention)                                        n-Norm[0][0]',                   \n",
      "                                                                  'Encoder-2-FeedForward-Norm[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'Encoder-2-FeedForward-Norm[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " Decoder-2-MultiHeadQueryAttent  (None, None, 32)    0           ['Decoder-2-MultiHeadQueryAttenti\n",
      " ion-Dropout (Dropout)                                           on[0][0]']                       \n",
      "                                                                                                  \n",
      " Decoder-2-MultiHeadQueryAttent  (None, None, 32)    0           ['Decoder-2-MultiHeadSelfAttentio\n",
      " ion-Add (Add)                                                   n-Norm[0][0]',                   \n",
      "                                                                  'Decoder-2-MultiHeadQueryAttenti\n",
      "                                                                 on-Dropout[0][0]']               \n",
      "                                                                                                  \n",
      " Decoder-2-MultiHeadQueryAttent  (None, None, 32)    64          ['Decoder-2-MultiHeadQueryAttenti\n",
      " ion-Norm (LayerNormalization)                                   on-Add[0][0]']                   \n",
      "                                                                                                  \n",
      " Decoder-2-FeedForward (FeedFor  (None, None, 32)    8352        ['Decoder-2-MultiHeadQueryAttenti\n",
      " ward)                                                           on-Norm[0][0]']                  \n",
      "                                                                                                  \n",
      " Decoder-2-FeedForward-Dropout   (None, None, 32)    0           ['Decoder-2-FeedForward[0][0]']  \n",
      " (Dropout)                                                                                        \n",
      "                                                                                                  \n",
      " Decoder-2-FeedForward-Add (Add  (None, None, 32)    0           ['Decoder-2-MultiHeadQueryAttenti\n",
      " )                                                               on-Norm[0][0]',                  \n",
      "                                                                  'Decoder-2-FeedForward-Dropout[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " Decoder-2-FeedForward-Norm (La  (None, None, 32)    64          ['Decoder-2-FeedForward-Add[0][0]\n",
      " yerNormalization)                                               ']                               \n",
      "                                                                                                  \n",
      " Decoder-Output (EmbeddingSim)  (None, None, 329)    329         ['Decoder-2-FeedForward-Norm[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'Decoder-Token-Embedding[0][1]']\n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 80,777\n",
      "Trainable params: 80,777\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Generate dictionaries\n",
    "def build_token_dict(token_list):\n",
    "    token_dict = {\n",
    "        '<PAD>': 0,\n",
    "        '<START>': 1,\n",
    "        '<END>': 2,\n",
    "    }\n",
    "    for tokens in token_list:\n",
    "        for token in tokens:\n",
    "            if token not in token_dict:\n",
    "                token_dict[token] = len(token_dict)\n",
    "    return token_dict\n",
    "\n",
    "source_token_dict = build_token_dict(source_tokens)\n",
    "target_token_dict = build_token_dict(target_tokens)\n",
    "target_token_dict_inv = {v: k for k, v in target_token_dict.items()}\n",
    "\n",
    "# Add special tokens\n",
    "encode_tokens = [['<START>'] + tokens + ['<END>'] for tokens in source_tokens]\n",
    "decode_tokens = [['<START>'] + tokens + ['<END>'] for tokens in target_tokens]\n",
    "output_tokens = [tokens + ['<END>', '<PAD>'] for tokens in target_tokens]\n",
    "\n",
    "# Padding\n",
    "source_max_len = max(map(len, encode_tokens))\n",
    "target_max_len = max(map(len, decode_tokens))\n",
    "\n",
    "encode_tokens = [tokens + ['<PAD>'] * (source_max_len - len(tokens)) for tokens in encode_tokens]\n",
    "decode_tokens = [tokens + ['<PAD>'] * (target_max_len - len(tokens)) for tokens in decode_tokens]\n",
    "output_tokens = [tokens + ['<PAD>'] * (target_max_len - len(tokens)) for tokens in output_tokens]\n",
    "\n",
    "encode_input = [list(map(lambda x: source_token_dict[x], tokens)) for tokens in encode_tokens]\n",
    "decode_input = [list(map(lambda x: target_token_dict[x], tokens)) for tokens in decode_tokens]\n",
    "decode_output = [list(map(lambda x: [target_token_dict[x]], tokens)) for tokens in output_tokens]\n",
    "\n",
    "# Build & fit model\n",
    "model = get_model(\n",
    "    token_num=max(len(source_token_dict), len(target_token_dict)),\n",
    "    embed_dim=32,\n",
    "    encoder_num=2,\n",
    "    decoder_num=2,\n",
    "    head_num=4,\n",
    "    hidden_dim=128,\n",
    "    dropout_rate=0.05,\n",
    "    use_same_embed=False,  # Use different embeddings for different languages\n",
    ")\n",
    "model.compile('adam', 'sparse_categorical_crossentropy')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6298a5e4-9e8c-4513-bc3e-149b7c1a7ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6240/6240 [==============================] - 165s 25ms/step - loss: 0.1641\n",
      "Epoch 2/10\n",
      "6240/6240 [==============================] - 163s 26ms/step - loss: 0.0049\n",
      "Epoch 3/10\n",
      "6240/6240 [==============================] - 151s 24ms/step - loss: 0.0043\n",
      "Epoch 4/10\n",
      "6240/6240 [==============================] - 150s 24ms/step - loss: 0.0038\n",
      "Epoch 5/10\n",
      "6240/6240 [==============================] - 150s 24ms/step - loss: 0.0043\n",
      "Epoch 6/10\n",
      "6240/6240 [==============================] - 153s 24ms/step - loss: 0.0036\n",
      "Epoch 7/10\n",
      "6240/6240 [==============================] - 153s 24ms/step - loss: 0.0036\n",
      "Epoch 8/10\n",
      "6240/6240 [==============================] - 151s 24ms/step - loss: 0.0036\n",
      "Epoch 9/10\n",
      "6240/6240 [==============================] - 150s 24ms/step - loss: 0.0038\n",
      "Epoch 10/10\n",
      "6240/6240 [==============================] - 152s 24ms/step - loss: 0.0037\n",
      "CPU times: user 51min 23s, sys: 3min 52s, total: 55min 16s\n",
      "Wall time: 25min 39s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f71bd2c5400>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(\n",
    "    x=[np.array(encode_input * 1024), np.array(decode_input * 1024)],\n",
    "    y=np.array(decode_output * 1024),\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932a17cf-eb43-4961-9fbf-c75d6c2d668e",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f1e46380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wow!\n",
      "Help!\n",
      "Jump.\n",
      "Jump.\n",
      "Jump.\n",
      "Hello!\n",
      "Hello!\n",
      "Cheers!\n",
      "Cheers!\n",
      "Got it?\n",
      "I'm OK.\n",
      "Awesome!\n",
      "Come in.\n",
      "Get out!\n",
      "Go away!\n",
      "Goodbye!\n",
      "Perfect!\n",
      "Perfect!\n",
      "Welcome.\n",
      "Welcome.\n",
      "Have fun.\n",
      "Have fun.\n",
      "Have fun.\n",
      "I forgot.\n",
      "I forgot.\n",
      "I'll pay.\n",
      "I'm fine.\n",
      "I'm full.\n",
      "Let's go!\n",
      "Answer me.\n",
      "Birds fly.\n",
      "Excuse me.\n",
      "Fantastic!\n",
      "I fainted.\n",
      "I fear so.\n",
      "I laughed.\n",
      "I'm bored.\n",
      "I'm broke.\n",
      "I am tired.\n",
      "It's cold.\n",
      "Who knows?\n",
      "Who knows?\n",
      "Who knows?\n",
      "Who knows?\n",
      "Wonderful!\n",
      "Birds sing.\n",
      "Come on in.\n",
      "Definitely!\n",
      "Don't move.\n",
      "Fire burns.\n",
      "Follow him.\n",
      "I am tired.\n",
      "I can swim.\n",
      "I can swim.\n",
      "I love you.\n",
      "I love you.\n",
      "I love you.\n",
      "I love you.\n",
      "I love you.\n",
      "I will try.\n",
      "I'm coming.\n",
      "I'm hungry!\n",
      "Let him in.\n",
      "Let him in.\n",
      "Let me out!\n",
      "Once again.\n",
      "Please sit.\n",
      "What's new?\n",
      "What's new?\n",
      "Who's that?\n",
      "Don't shout.\n",
      "Don't shout.\n",
      "He stood up.\n",
      "He's strong.\n",
      "How are you?\n",
      "How are you?\n",
      "How are you?\n",
      "How are you?\n",
      "How are you?\n",
      "How are you?\n",
      "How are you?\n",
      "How are you?\n",
      "I like both.\n",
      "I like cake.\n",
      "I like dogs.\n",
      "I like math.\n",
      "I'll attend.\n",
      "Nobody came.\n",
      "Was I wrong?\n",
      "What is this?\n",
      "Are you sick?\n",
      "Bring him in.\n",
      "Come with us.\n",
      "Happy Easter!\n",
      "Has Tom left?\n",
      "He is French.\n",
      "I am at home.\n",
      "I can't move.\n",
      "I don't know.\n",
      "I don't know.\n",
      "I have a car.\n",
      "I have a dog.\n",
      "I understand.\n",
      "I'm a doctor.\n",
      "I'm starving!\n",
      "It is a book.\n",
      "It's snowing.\n",
      "It's too big.\n",
      "Please leave.\n",
      "Unbelievable!\n",
      "We are happy.\n",
      "What is this?\n",
      "Are you tired?\n",
      "Can you drive?\n",
      "Don't get fat.\n",
      "Don't give in.\n",
      "Drink it down.\n",
      "Everyone dies.\n",
      "Flowers bloom.\n",
      "I am who I am.\n",
      "I'll take him.\n",
      "I'm tired now.\n",
      "I'm very busy.\n",
      "Is that a cat?\n",
      "It's for free.\n",
      "It's for free.\n",
      "Let me try it.\n",
      "Let me try it.\n",
      "Let me try it.\n",
      "Make it quick.\n",
      "May I come in?\n",
      "Open the door.\n",
      "Open the door.\n",
      "Please get in.\n",
      "Read it again.\n",
      "Read it aloud.\n",
      "She bent down.\n",
      "Some fish fly.\n",
      "This is a map.\n",
      "Tom is my son.\n",
      "We're in town.\n",
      "Were you shot?\n",
      "What about us?\n",
      "Can I help you?\n",
      "Can I help you?\n",
      "Clean the room.\n",
      "Don't touch it.\n",
      "Get out of bed!\n",
      "Happy New Year!\n",
      "Happy New Year!\n",
      "Happy birthday!\n",
      "He has a beard.\n",
      "He is an actor.\n",
      "He needs money.\n",
      "He was hard up.\n",
      "I like history.\n",
      "I like the dog.\n",
      "I must buy one.\n",
      "I'll come back.\n",
      "I'll phone you.\n",
      "I'll stay home.\n",
      "I'm an atheist.\n",
      "I'm an atheist.\n",
      "I'm very tired.\n",
      "It's hot today.\n",
      "This is a book.\n",
      "It's your move.\n",
      "Only God knows.\n",
      "Summer is over.\n",
      "Take your time.\n",
      "Think about it.\n",
      "This is a book.\n",
      "This is a book.\n",
      "This is my bag.\n",
      "This is my dog.\n",
      "Wash your feet.\n",
      "We study music.\n",
      "We'll call you.\n",
      "We'll call you.\n",
      "Where were you?\n",
      "Where were you?\n",
      "You have to go.\n",
      "You look tired.\n",
      "You're kidding!\n",
      "A man must work.\n",
      "Are you at home?\n",
      "Are you guys OK?\n",
      "Come home early.\n",
      "Come if you can.\n",
      "Congratulations!\n",
      "Congratulations!\n",
      "Did he go there?\n",
      "Did you miss me?\n",
      "Don't be absurd.\n",
      "He came running.\n"
     ]
    }
   ],
   "source": [
    "decoded = decode(\n",
    "    model,\n",
    "    encode_input,\n",
    "    start_token=target_token_dict['<START>'],\n",
    "    end_token=target_token_dict['<END>'],\n",
    "    pad_token=target_token_dict['<PAD>'],\n",
    ")\n",
    "for i in decoded:\n",
    "    print(' '.join(map(lambda x: target_token_dict_inv[x], i[1:-1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115972a8-4f67-4aba-a726-7edb51e1c044",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9890f24c-1f85-4edb-b367-61108409fb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sents = [\n",
    "    'kaise ho?',\n",
    "    'kya tum mujhse pyar karte ho?',\n",
    "    'kya tum mujhe pyar karte ho?'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c8dc7e12-c0bd-4aee-b665-dfedc2e9abfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tokens = [i.split() for i in test_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "10df85f1-1b12-4261-921b-2d942b169b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_token_dict = build_token_dict(test_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a78b347a-7fe8-4926-bccc-25eb45bfd8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_token_dict_inv = {v: k for k, v in test_token_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "24d65795-01db-4798-8b2b-6d42a4c32cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_enc_tokens = [['<START>'] + tokens + ['<END>'] for tokens in test_tokens]\n",
    "test_enc_tokens = [tokens + ['<PAD>'] * (target_max_len - len(tokens)) for tokens in test_enc_tokens]\n",
    "test_input = [list(map(lambda x: test_token_dict[x], tokens)) for tokens in test_enc_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "21be3596-52cd-4761-b2a9-595f54cb0df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wow!\n",
      "I can't you?\n",
      "I can't now.\n"
     ]
    }
   ],
   "source": [
    "decoded = decode(\n",
    "    model,\n",
    "    test_input,\n",
    "    start_token=test_token_dict['<START>'],\n",
    "    end_token=test_token_dict['<END>'],\n",
    "    pad_token=test_token_dict['<PAD>'],\n",
    ")\n",
    "for i in decoded:\n",
    "    print(' '.join(map(lambda x: target_token_dict_inv[x], i[1:-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd4e4ca-58f8-4715-902b-d872b59aa6dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1982e90c-3e54-4623-9595-c8a65639029a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_translation_py38",
   "language": "python",
   "name": "nlp_translation_py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
